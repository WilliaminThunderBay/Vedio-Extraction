 Hi, welcome back. This is section 1 and we're going to introduce Computer Vision. Computer Vision is an exciting space in machine learning. You can think of Computer Vision as the automated extraction of information from digital images. Using Computer Vision, machines can identify people, places, and things in images with an accuracy that's at or above human levels and with greater speed and efficiency. Computer Vision is often built with deep learning models. It automates the extraction, analysis, classification, and understanding of useful information from a single image or a sequence of images. The image data can take many forms, such as single images, video sequences, views from multiple cameras, or three-dimensional data. Computing power and algorithms have advanced over the last 10 years. This has led to an increase in capabilities and easier access to Computer Vision technologies. So how is Computer Vision being used? Here are some of the primary use cases for Computer Vision. You can use image and facial recognition to improve public safety and home security, or as a way to authenticate access to personal devices. You can also use it to automatically classify images for content management and analysis. Autonomous driving is partly enabled by Computer Vision technologies, and so are safety features of cars, such as lane detection or collision avoidance. Medical image analysis with Computer Vision can improve the accuracy and speed of a patient's medical diagnosis. This can result in better treatment outcomes and life expectancy for the patient. And finally, in manufacturing, well-trained Computer Vision is incorporated into robotics. This can improve quality assurance and operational efficiencies. These are just a few examples, and you can probably think of more. Computer Vision problems can be broken down into a few areas. Content recognition is about identifying things in images. It's a classification problem, but it's a complex one with several layers. In the picture here, what's represented? Is it breakfast, lunch, or dinner? Would the classification only be food? The answer depends on what model you use to perform the classification. Models must be trained, and the training data provides the algorithm with data for it to learn from. Say that you have a model that was trained with pictures of different types of food. You might expect the image to output categories such as milk, peaches, mashed potato, chicken nuggets, and salad. If you trained the model with different images, it could classify objects as tray, cutlery, and napkin instead. When you work with images, you might want to know what kinds of objects are in the image and the location of those objects. Object detection provides the image categories and where the objects are located in the image. There's a set of coordinates defining the location of a box surrounding the image, which is known as the bounding box. Bounding boxes for detection are typically top, left, width, and height coordinates surrounding the images. You can use these coordinates in your applications. When objects are detected in an image, there's a confidence number usually associated with that object. This percentage indicates the probability that the object belongs to a specific class. This confidence level is important when you want to determine an action that's based on object detection, especially in facial detection applications, or cases where the action has significance. Object segmentation is also known as semantic segmentation. It's like object detection, but you go into more detail to get fine boundaries for each detected object. Basically, it's a fine-grained inference for predicting each pixel in the image. Some applications that require object segmentation include autonomous vehicles and advanced computer-human interactions. Though object segmentation is a key problem in the field of computer vision, we won't be covering it in this course. Video adds another dimension to computer vision. With video, you get more data to work with, so you can capture the movement of people or objects which are referred to as instances. For example, you can detect people who enter and leave frames, and also deal with moving cameras. Here's a use case for computer vision. Building on detection and tracking, you can analyze shopper behavior in your retail store by studying the path each person follows. If you use face analysis, you can understand other details about shoppers, such as average age ranges, gender distribution, and expressed emotions without identifying them. Here's another computer vision use case. You can also analyze images to identify actions using the motion in the video. For example, activities such as delivering a package or dancing. Looking at this image of a baseball player, some examples from the image could include capturing the batter's accuracy, the pitcher's pitching style, the type of pitch, slowball, slider, and others, the inning, and the batter's performance versus the specific pitcher. Managers could use all that data to coach players on how to improve their performance, and they do. Players can also use the data during the game to make game time decisions. Say you want to initiate various actions based on the speed of the baseball leaving the bat and its trajectory. A hit that's calculated by an ML model could lead to an audio or visual warning about a possible foul ball into the crowd. Or it could result in a preemptive alarm that a hit has a high probability of being a home run. This means that events following a home run could be both well timed and automated, such as playing music or setting off fireworks when the home run is hit by the home team. To wrap up this section, here are some key takeaways for this section. First, we covered how computer vision is the automated extraction of information from images. You can divide computer vision into two distinct areas, image analysis and video analysis. Image analysis includes object classification, detection, and segmentation. Video analysis includes instance tracking, action recognition, and motion estimation. Thanks for watching, we'll see you in the next video.