 Hi, and welcome to section 4. In this section, we're going to look at feature engineering. Feature engineering is one of the most impactful things you can do to improve your machine learning model. We'll now look at what it is. There are two things that can help make your models more successful. The first is feature selection, and the second is feature extraction, or the process of creating features. In feature selection, you select the most relevant features and discard the rest. You can apply feature selection to prevent redundancy or irrelevance in the existing features. You can also use it to limit the number of features to help prevent overfitting. Feature extraction builds valuable information from raw data by reformatting, combining, and transforming primary features into new ones. This process continues until it yields a new dataset that can be consumed by the model to achieve your goals. As the diagram shows, feature extraction covers a range of activities, from dealing with missing data to converting text data into numerical data. Although the list isn't exhaustive, it should give you some idea of the data handling that's needed to get data into a useful state. Many of the tasks are no different than any other job working with data. You'll want to make sure data is in the correct format, that it's consistently represented, correctly spelled, among other tasks. For example, you might combine data or extract data into multiple columns, or you could also remove columns altogether. Similar to machine learning, you'll need to convert text columns to numerical values. You'll also need to decide how to handle outliers and potentially rescale your data. Next, we'll look at some of the more common tasks in this section. Most machine learning algorithms work best with numerical data. You'll need to make sure that all columns in your dataset contain numeric data by converting or encoding it. You might need to make several passes through the datasheet before you can encode it. For example, you might have variability in the text values, such as rows that contain both medium and MED as values. If the categorical data has order to it, you'll want to encode the text into numerical values that capture this ordinal relationship. Say you have data showing maintenance costs. You might encode low to 1, medium to 2, high to 3, and very high to 4. After you've made sure your categorical data is all uniform, you can use tools like Skykit Learn and Pandas to encode your data. If the categorical data doesn't have any order to it, then you'll need to break the data into multiple columns. This will help make sure you don't introduce an ordinal relationship to the data that isn't there. For example, suppose you assigned a value of 1 to the first color, such as red, and you then assigned 2 to the next value, say blue. The model could interpret blue as being more important than red because blue has a higher numeric value. Encoding non-ordinal data into multiple columns or features is a better way. Think of the new features like a checkbox. Consider the example. There are three features that were generated. The value 1 indicates that the instance has that feature, like its color. That's it for this section. We'll see you again in the next video.