 Hi, and welcome back. In this section, we'll look at how you can use Amazon Forecast to create a predictor and generate forecasts. When you generate forecasts, you can apply the Machine Learning Development Pipeline you've seen throughout this course, but you still need data. You need to import as much data as you have, both historical data and related data. You'll want to do some basic evaluation and feature engineering before you use the data to train a model so you can meet the requirements of Amazon Forecast. To train a predictor, you need to choose an algorithm. If you're not sure which algorithm is the best for your data, Amazon Forecast can choose for you. To do this, select AutoML as your algorithm. You also need to select a domain for your data. If you're not sure what the best fit is, you can also select a custom domain. Domains have specific types of data they require. When you have a trained model, you can then use the model to make a forecast using an input data set group. After you've generated a forecast, you can query the forecast. You can also export it to a bucket in Amazon S3. And finally, you can encrypt the data in the forecast before exporting it. The overall process for working with Amazon Forecast is to import historical and related data. Amazon Forecast inspects the data, identifies key data, and selects an appropriate algorithm. It uses the algorithm to train and optimize a custom model and produce a predictor. You create forecasts by applying the predictor to your data set. You can then retrieve these forecasts in the AWS Management Console, or you can export the forecasts as common delimited files. You can also use an API and AWS CLI commands to create and retrieve forecasts. When you work with Amazon Forecast, you can select the domain you're working in. There are domains ranging from retail to web traffic, and there's also a custom option for everything else. By selecting a domain, you improve the efficiency of the predictor. Each domain has specific types of data that you'll supply when you build the predictor. For example, the retail domain expects data for the item identifiers, a timestamp for the observation, the number of sales for that item, and the specified timestamp. Here's an example of the data you'd need to provide for a retail demand forecast. For the time series, you need the time when the transaction took place, ideally in UTC format, the item ID of the item, and how many items were sold. The metadata for the item might include the category, the item color, and other attributes. The link back to the time series data will be only the item ID, because item metadata typically doesn't change. Related data for creating a more useful forecast could include the sales price or other promotion data. To link this back to the item, you must include the timestamp and the item ID. Here's an example of the data you'd need to provide for a web traffic forecast. For the time series, you need the web page ID, the number of page views per month, and the timestamp. Related data for creating a more useful forecast could include the page category, such as navigation or content category. You'll also need the geographic identifier for the web client. For metadata, you might also need to provide the region and the sales promotion information. Amazon forecast predictors use an algorithm to train a model. They then use the model to make a forecast using an input dataset group. To help you get started, Amazon forecast provides predefined algorithms, ARIMA, DEPAR+, ETS, NPTS, and PROPHET. You can also use the AutoML feature. It will try all the algorithms to see which one's at the best at predicting data. When you prepare data for training and machine learning, you typically hold back data to use when you validate and score the model. The data that you hold back is usually a random sample of your available data. With time series data, you must process your data differently because of a correlation between time. When you import your data, Amazon forecast breaks it into training and test datasets, which the diagram shows. The training data is used to train the model, which is then tested against the data that was held back. You can specify multiple back test windows, which will split the data multiple times, train the model, and use metrics to determine which model gives the best results. The default back test window is one. You can change how Amazon forecast splits the data by setting the back test window offset parameter when you create the predictor. If you don't set this value, the algorithms use default values. After you've trained a model, you will need to measure its accuracy, which you will learn about next. The first Amazon forecast evaluation metric is the weighted quantile loss, or W quantile loss. When Amazon forecast creates a forecast, it provides probabilistic predictions at three distinct quantiles, 10%, 50%, and 90%. These prediction quantiles show you how much uncertainty is associated with each forecast. A P10 quantile predicts that 10% of the time the true value will be less than the predicted value. For example, suppose that you are a retailer. You want to forecast product demand for winter gloves that sell well only during the fall and winter. Say that you don't have sufficient storage space and the cost of invested capital is high, or that the price of being overstocked on winter gloves concerns you. Then you might use the P10 quantile to order a relatively low number of winter gloves. You know that the P10 forecast overestimates the demand for your winter gloves only 10% of the time, so you'll be sold out of your winter gloves for 90% of the time. A P50 quantile predicts that 50% of the time the true value will be less than the predicted value. Continuing the winter gloves example, say you know that there will be a moderate amount of demand for the gloves, and you aren't concerned about being overstocked. Then you might choose to use the P50 quantile to order gloves. A P90 quantile predicts that 90% of the time the true value will be less than the predicted value. Suppose you determine that being understocked on gloves will result in large amounts of lost revenue. For example, the cost of not selling gloves is extremely high, or the cost of invested capital is low. In this case, you might choose to use the P90 quantile to order gloves. Amazon forecast also calculates the associated loss or error at each quantile. P50 quantile loss calculates how far off the forecast a certain quantile is from actual demand in either direction. Lower W quantile loss metrics mean that the model's forecasts are more reliable. The root mean square error, or RMSE, is another method for evaluating the reliability of your forecasts. Like W quantile loss, RMSE calculates how far off the forecasted values were from the actual test data. The RMSE finds the difference between the actual target value in the dataset and the forecasted value for that time period, and it then squares the differences. The example shows how to calculate RMSE. The RMSE value represents the standard deviation of the prediction errors. This test is good for forecast validity when the errors are mostly of the same size, that is, there aren't many outliers. Lower RMSE metrics indicate that the model's forecasts are more reliable. Here's an example of how a web retailer might use the accuracy metrics to evaluate a forecast. The retailer wants to predict the demand for sales of a particular brand of shoes. They input the sales records for this brand into Amazon Forecast to create a predictor. The predictor provides a forecasted demand of 1,000 pairs with the P10, P50, and P90 values shown. The weighted quantile loss values indicate that 10% of the time there will be fewer than 880 pairs sold. 50% of the time, fewer than 1,050 pairs will be sold. And 90% of the time, fewer than 1,200 pairs will be sold. The retailer can then use these values to determine which level of inventory to hold. They can base their decision on their assessment of the risk that they won't be able to fulfill orders, or that they'll have excess inventory. Some key takeaways from this section of the module include you can use Amazon Forecast to train and use a model for time series data. There are specific schemas defined for domains such as retail and EC2 capacity planning, or you can use a custom schema. You need to supply at least the time series data, but can also provide metadata and related data to add more information to the model. As with most supervised machine learning problems, your data is split into training and testing data, but takes into account the time element. Use RMSE and WQuantileLoss metrics to evaluate the efficiency of the model. That's it for this video, we'll see you in the next one.